{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwILkW1F8FnJ"
   },
   "source": [
    "# Project: Second-Order HMM for typos correction\n",
    "\n",
    "\n",
    "\n",
    "The goal is to design a model to correct typos in texts without a dictionaries.\n",
    "\n",
    "In this problem, a state refers to the correct letter that should have been typed, and an observation refers to the actual letter that is typed. Given a sequence of outputs/observations (i.e., actually typed letters), the problem is to reconstruct the hidden state sequence (i.e., the intended sequence of letters). Thus, data for this problem looks like:\n",
    "\n",
    "* [('t', 't'), ('h', 'h'), ('w', 'e'), ('k', 'm')]\n",
    "* [('f', 'f'), ('o', 'o'), ('r', 'r'), ('m', 'm')] \n",
    "\n",
    "The first example is misspelled: the observation is thwk while the correct word is them. The second example is correctly typed.\n",
    "\n",
    "Data for this problem was generated as follows: starting with a text document, in this case, the Unabomber's Manifesto, which was chosen not for political reasons, but for its convenience being available on-line and of about the right length, all numbers and punctuation were converted to white space and all letters converted to lower case. The remaining text is a sequence only over the lower case letters and the space character, represented in the data files by an underscore character. Next, typos were artificially added to the data as follows: with 90% probability, the correct letter is transcribed, but with 10% probability, a randomly chosen neighbor (on an ordinary physical keyboard) of the letter is transcribed instead. Space characters are always transcribed correctly. In a harder variant of the problem, the rate of errors is increased to 20%.\n",
    "\n",
    "The dataset in an archive, see the shared drive to download it. This archive contains 4 pickles: train10 and test10 constitute the dataset with 10% or spelling errors, while train20 and test20 the one with 20% or errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : First Order HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtP9d0Pz8FnL"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy import array, ones, zeros\n",
    "import sys\n",
    "\n",
    "class HMM:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print(\"HMM created with: \")\n",
    "            self.N = len(state_list) # The number of states\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            print(str(self.N)+\" states\")\n",
    "            print(str(self.M)+\" observations\")\n",
    "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
    "            self.omega_X = observation_list # Keep the vocabulary of tags\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros( (self.N,), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.make_indexes()\n",
    "\n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            omega_Y_keys = [key for key in self.omega_Y.keys()]\n",
    "            omega_X_keys = [key for key in self.omega_X.keys()]\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[omega_Y_keys[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[omega_X_keys[i]] = i\n",
    "                \n",
    "        def get_X_index(self, word):\n",
    "            if word in self.X_index:\n",
    "                return word\n",
    "            else:\n",
    "                return UNK\n",
    "        \n",
    "        def compute_init_state_proba(self, data):\n",
    "            for sent in data:\n",
    "                self.initial_state_proba[self.Y_index[sent[0][1]]]+=1\n",
    "            self.initial_state_proba/=len(data)\n",
    "            \n",
    "        def compute_observation_probas(self, data):            \n",
    "            for phr in data:\n",
    "                for word in phr:\n",
    "                    x = self.X_index[self.get_X_index(word[0])]\n",
    "                    y = self.Y_index[word[1]]\n",
    "                    self.observation_proba[x][y] += 1\n",
    "            self.observation_proba /= np.sum(self.observation_proba, axis=1)[:, np.newaxis]\n",
    "             \n",
    "        def compute_transition_probas(self, data):            \n",
    "            for phr in data:\n",
    "                for i in range(len(phr) - 1):\n",
    "                    yplus1 = self.Y_index[phr[i + 1][1]]\n",
    "                    y = self.Y_index[phr[i][1]]\n",
    "                    self.transition_proba[y][yplus1] += 1\n",
    "            self.transition_proba /= np.sum(self.transition_proba, axis=1)[:, np.newaxis]\n",
    "            \n",
    "        def init_parameters(self, train_set):\n",
    "            self.compute_init_state_proba(train_set)\n",
    "            self.compute_observation_probas(train_set)\n",
    "            self.compute_transition_probas(train_set)\n",
    "            \n",
    "        def forward(self, obs):\n",
    "            alpha = np.zeros((len(obs), len(self.Y_index)))\n",
    "            alpha[0] = self.initial_state_proba\\\n",
    "                        * self.observation_proba[self.X_index[self.get_X_index(obs[0][0])]]\n",
    "            for i in range(1, len(alpha)):\n",
    "                alpha[i] = self.observation_proba[self.X_index[self.get_X_index(obs[i][0])]] *\\\n",
    "                np.sum(self.transition_proba.T * alpha[i - 1], axis=1)\n",
    "            return alpha\n",
    "        \n",
    "        def backward(self, obs):\n",
    "            beta = np.zeros((len(obs), len(self.Y_index)))\n",
    "            beta[-1] = ones(len(self.Y_index))\n",
    "            for i in range(len(obs) - 2, -1, -1):\n",
    "                beta[i] = np.sum(beta[i + 1]\\\n",
    "                                 * self.observation_proba[self.X_index[self.get_X_index(obs[i + 1][0])]]\\\n",
    "                                 * self.transition_proba, axis=1)\n",
    "            return beta\n",
    "        \n",
    "        def decode(self, alpha, beta):\n",
    "            prob = alpha * beta\n",
    "            preds = prob.argmax(axis=1)\n",
    "            keys = [key for key in self.omega_Y.keys()]\n",
    "            return [keys[pred_ind] for pred_ind in preds]\n",
    "        \n",
    "        def viterbi(self, obs):\n",
    "            mu_max = np.zeros(len(obs))\n",
    "            tmp = self.initial_state_proba * self.observation_proba[self.X_index[self.get_X_index(obs[0][0])]]\n",
    "            index = [np.argmax(tmp)]\n",
    "            mu_max[0] = max(tmp)\n",
    "            for i in range(1, len(obs)):\n",
    "                tmp = self.observation_proba[self.X_index[self.get_X_index(obs[i][0])]]\\\n",
    "                        * self.transition_proba[self.Y_index[obs[i - 1][1]]]\\\n",
    "                        * mu_max[i - 1]\n",
    "                index.append(np.argmax(tmp))\n",
    "                mu_max[i] = max(tmp)\n",
    "            keys = [key for key in self.omega_Y.keys()]\n",
    "            return [keys[ind] for ind in index]\n",
    "            \n",
    "        def score_eval(self, test):\n",
    "            error = 0\n",
    "            elements = 0\n",
    "            errors_corrected = 0\n",
    "            errors_added = 0\n",
    "            for word in test:\n",
    "                base = [letter for (letter, _) in word]\n",
    "                truth = [tag for (_, tag) in word]\n",
    "                alpha = self.forward(word)\n",
    "                beta = self.backward(word)\n",
    "                preds = self.decode(alpha, beta)\n",
    "                elements += len(preds)\n",
    "                for x, y, pred in zip(base, truth, preds):\n",
    "                    if pred != x and pred == y:\n",
    "                        errors_corrected += 1\n",
    "                    if pred != y:\n",
    "                        error += 1\n",
    "                        if x == y:\n",
    "                            errors_added += 1\n",
    "            return error / elements, errors_corrected, errors_added\n",
    "        \n",
    "        def score_viterbi(self, test):\n",
    "            error = 0\n",
    "            elements = 0\n",
    "            errors_corrected = 0\n",
    "            errors_added = 0\n",
    "            for word in test:\n",
    "                base = [letter for (letter, _) in word]\n",
    "                truth = [tag for (_, tag) in word]\n",
    "                preds = self.viterbi(word)\n",
    "                elements += len(preds)\n",
    "                for x, y, pred in zip(base, truth, preds):\n",
    "                    if pred != x and pred == y:\n",
    "                        errors_corrected += 1\n",
    "                    if pred != y:\n",
    "                        error += 1\n",
    "                        if x == y:\n",
    "                            errors_added += 1\n",
    "            return error / elements, errors_corrected, errors_added\n",
    "\n",
    "        def score_dummy(self, test):\n",
    "            error = 0\n",
    "            elements = 0\n",
    "            for word in test:\n",
    "                base = [letter for (letter, _) in word]\n",
    "                truth = [tag for (_, tag) in word]\n",
    "                elements += len(truth)\n",
    "                for x, y in zip(base, truth):\n",
    "                    if x != y:\n",
    "                        error += 1\n",
    "            return error / elements\n",
    "        \n",
    "        def results_hmm(self, test):\n",
    "            error_test, fb_corrected, fb_added = self.score_eval(test)\n",
    "            viterbi_error_test, vit_corrected, vit_added = self.score_viterbi(test)\n",
    "            error_dummy = self.score_dummy(test)\n",
    "            print(\"Error forward-backward = {:.2%}, {} errors corrected, {} errors added\"\n",
    "                  .format(error_test, fb_corrected, fb_added))\n",
    "            print(\"Error viterbi = {:.2%}, {} errors corrected, {} errors added\"\n",
    "                  .format(viterbi_error_test, vit_corrected, vit_added))\n",
    "            print(\"Error with nothing changed = {:.2%}\".format(error_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture & séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YO0E0GvD8FnS"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train10 = pickle.load(open(\"./typos-data/train10.pkl\", \"rb\"))\n",
    "train20 = pickle.load(open(\"./typos-data/train20.pkl\", \"rb\"))\n",
    "test10 = pickle.load(open(\"./typos-data/test10.pkl\", \"rb\"))\n",
    "test20 = pickle.load(open(\"./typos-data/test20.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du vocabulaire & du HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distrib_x_y_data(data):\n",
    "    set_tag = []\n",
    "    set_mot = []\n",
    "    dict_tag = dict()\n",
    "    dict_mot = dict()\n",
    "    for phrase in data:\n",
    "        for mot in phrase:\n",
    "            if not(mot[1] in set_tag):\n",
    "                set_tag.append(mot[1])\n",
    "                dict_tag[mot[1]]=0\n",
    "            dict_tag[mot[1]]+=1\n",
    "            if not(mot[0] in set_mot):\n",
    "                set_mot.append(mot[0])\n",
    "                dict_mot[mot[0]]=0\n",
    "            dict_mot[mot[0]]+=1\n",
    "    return dict_mot, dict_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus with 10% errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM created with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "obs_list, state_list = distrib_x_y_data(train10)\n",
    "\n",
    "hmm = HMM(state_list, obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error forward-backward = 8.29%, 332 errors corrected, 194 errors added\n",
      "Error viterbi = 8.92%, 296 errors corrected, 204 errors added\n",
      "Error baseline = 10.18%\n"
     ]
    }
   ],
   "source": [
    "hmm.init_parameters(train10)\n",
    "\n",
    "hmm.results_hmm(test10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus with 20% errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM created with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "obs_list, state_list = distrib_x_y_data(train20)\n",
    "\n",
    "hmm_20 = HMM(state_list, obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error forward-backward = 15.04%, 1453 errors corrected, 724 errors added\n",
      "Error viterbi = 15.85%, 1401 errors corrected, 808 errors added\n",
      "Error baseline = 19.41%\n"
     ]
    }
   ],
   "source": [
    "hmm_20.init_parameters(train20)\n",
    "\n",
    "hmm_20.results_hmm(test20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Second order HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy import array, ones, zeros\n",
    "import sys\n",
    "\n",
    "class HMM_2:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ijk] a_ijk = Pr(Y_(t+1)=q_i|Y_t=q_j, Y_(t-1)=q_k)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_kij] b_ki = Pr(X_t=v_k|Y_t=q_i, Y_(t-1)=q_j)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print(\"HMM created with: \")\n",
    "            self.N = len(state_list) # The number of states\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            print(str(self.N)+\" states\")\n",
    "            print(str(self.M)+\" observations\")\n",
    "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
    "            self.omega_X = observation_list # Keep the vocabulary of tags\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros((self.N, self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros((self.M, self.N, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros((self.N,), float) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.transition_proba_order1 = zeros( (self.N, self.N), float) \n",
    "            self.observation_proba_order1 = zeros( (self.M, self.N), float) \n",
    "            self.make_indexes()\n",
    "\n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            omega_Y_keys = [key for key in self.omega_Y.keys()]\n",
    "            omega_X_keys = [key for key in self.omega_X.keys()]\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[omega_Y_keys[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[omega_X_keys[i]] = i\n",
    "                \n",
    "        def get_X_index(self, word):\n",
    "            if word in self.X_index:\n",
    "                return word\n",
    "            else:\n",
    "                return UNK\n",
    "        \n",
    "        def compute_init_state_proba(self, data):\n",
    "            for sent in data:\n",
    "                self.initial_state_proba[self.Y_index[sent[0][1]]]+=1\n",
    "            self.initial_state_proba/=len(data)\n",
    "        \n",
    "        def compute_observation_probas_order1(self, data):            \n",
    "            for phr in data:\n",
    "                for word in phr:\n",
    "                    x = self.X_index[self.get_X_index(word[0])]\n",
    "                    y = self.Y_index[word[1]]\n",
    "                    self.observation_proba_order1[x][y] += 1\n",
    "            self.observation_proba_order1 /= np.sum(self.observation_proba_order1, axis=1)[:, np.newaxis]\n",
    "             \n",
    "        def compute_transition_probas_order1(self, data):            \n",
    "            for phr in data:\n",
    "                for i in range(len(phr) - 1):\n",
    "                    yplus1 = self.Y_index[phr[i + 1][1]]\n",
    "                    y = self.Y_index[phr[i][1]]\n",
    "                    self.transition_proba_order1[y][yplus1] += 1\n",
    "            self.transition_proba_order1 /= np.sum(self.transition_proba_order1, axis=1)[:, np.newaxis]\n",
    "            \n",
    "        def compute_observation_probas(self, data):            \n",
    "            for phr in data:\n",
    "                for i in range(1, len(phr)):\n",
    "                    x = self.X_index[self.get_X_index(phr[i][0])]\n",
    "                    y = self.Y_index[phr[i][1]]\n",
    "                    yminus1 = self.Y_index[phr[i - 1][1]]\n",
    "                    self.observation_proba[x][yminus1][y] += 1\n",
    "            sumPlus1 = np.sum(self.observation_proba, axis=2)[:, :, np.newaxis]\n",
    "            self.observation_proba /= np.where(sumPlus1 == 0, 1, sumPlus1)\n",
    "             \n",
    "        def compute_transition_probas(self, data):  \n",
    "            nb_trigrams = 0.0\n",
    "            nb_bigrams = 0.0\n",
    "            unigram = zeros(self.N)\n",
    "            bigrams = zeros((self.N, self.N))\n",
    "            trigrams = zeros((self.N, self.N, self.N))\n",
    "            for phr in data:\n",
    "                for i in range(2, len(phr)):\n",
    "                    y = self.Y_index[phr[i][1]]\n",
    "                    unigram[y] += 1\n",
    "                    yminus1 = self.Y_index[phr[i - 1][1]]\n",
    "                    bigrams[yminus1][y] += 1\n",
    "                    nb_bigrams += 1.0\n",
    "                    yminus2 = self.Y_index[phr[i - 2][1]]\n",
    "                    trigrams[yminus2][yminus1][y] += 1\n",
    "                    nb_trigrams += 1.0\n",
    "#             unigram /= np.sum(unigram)\n",
    "#             bigrams /= np.sum(bigrams, axis=1)\n",
    "#             trigrams /= np.sum(trigrams, axis=2)\n",
    "#             print(\"Unigrams\\n\", unigram)\n",
    "#             print(\"Bigrams\\n\", bigrams)\n",
    "#             print(\"Trigrams\\n\", trigrams)\n",
    "            freq_bigrams = bigrams / nb_bigrams\n",
    "#             print(\"Freq bigrams\\n\", freq_bigrams)\n",
    "            freq_trigrams = trigrams / nb_trigrams\n",
    "#             print(\"Freq trigrams\\n\", freq_trigrams)\n",
    "            k3 = (np.log(freq_trigrams + 1) + 1) / (np.log(freq_trigrams + 1) + 2)\n",
    "            k2 = (np.log(freq_bigrams + 1) + 1) / (np.log(freq_bigrams + 1) + 2)\n",
    "#             print(\"K3\\n\", k3)\n",
    "#             print(\"K2\\n\", k2)\n",
    "            lambda1 = k3\n",
    "            lambda2 = (1 - k3) * k2\n",
    "            lambda3 = (1 - k3) * (1 - k2)\n",
    "            for phr in data:\n",
    "                for i in range(2, len(phr)):\n",
    "                    y = self.Y_index[phr[i][1]]\n",
    "                    yminus1 = self.Y_index[phr[i - 1][1]]\n",
    "                    yminus2 = self.Y_index[phr[i - 2][1]]\n",
    "                    self.transition_proba[yminus2][yminus1][y] = lambda1[yminus2][yminus1][y] \\\n",
    "                                                * trigrams[yminus2][yminus1][y]\\\n",
    "                                                + lambda2[yminus2][yminus1][y] * bigrams[yminus1][y]\\\n",
    "                                                + lambda3[yminus2][yminus1][y] * unigram[y]\n",
    "                    \n",
    "            sumPlus1 = np.sum(self.transition_proba, axis=2)[:, :, np.newaxis]\n",
    "            self.transition_proba /= np.where(sumPlus1 == 0, 1, sumPlus1)\n",
    "#             print((self.transition_proba > 0).sum())\n",
    "            \n",
    "        def init_parameters(self, train_set):\n",
    "            self.compute_init_state_proba(train_set)\n",
    "            self.compute_observation_probas(train_set)\n",
    "            self.compute_transition_probas(train_set)\n",
    "            self.compute_observation_probas_order1(train_set)\n",
    "            self.compute_transition_probas_order1(train_set)\n",
    "        \n",
    "        def viterbi(self, obs):\n",
    "            keys = [key for key in self.omega_Y.keys()]\n",
    "            \n",
    "            delta = np.zeros(len(obs))\n",
    "            tmp = self.initial_state_proba * self.observation_proba_order1\\\n",
    "                                                    [self.X_index[self.get_X_index(obs[0][0])]]\n",
    "            phi = [np.argmax(tmp)]\n",
    "            delta[0] = max(tmp)\n",
    "            \n",
    "            if len(obs) < 2:\n",
    "                return [keys[ind] for ind in phi]\n",
    "            else:\n",
    "\n",
    "                tmp2 = self.observation_proba[self.X_index[self.get_X_index(obs[1][0])]]\\\n",
    "                                                    [self.Y_index[obs[0][1]]]\\\n",
    "                            * self.transition_proba_order1[self.Y_index[obs[0][1]]]\\\n",
    "                            * delta[0]\n",
    "                phi.append(np.argmax(tmp2))\n",
    "                print(\"tag 0\", obs[0][1])\n",
    "                print(\"Letter 1\", obs[1][0])\n",
    "                print(\"Obs : curr_obs\", obs[1][0],\n",
    "                      \"last tag\", obs[0][1], \n",
    "                      \":\", dict(zip(keys, self.observation_proba[self.X_index[self.get_X_index(obs[1][0])]]\\\n",
    "                                                    [self.Y_index[obs[0][1]]])))\n",
    "                print(\"Transition :\", \"y - 1 :\", obs[0][1], \":\", \n",
    "                      dict(zip(keys, self.transition_proba_order1[self.Y_index[obs[0][1]]])))\n",
    "                print(\"Tmp2\", dict(zip(keys, tmp2)))\n",
    "                print(\"Chosen letter :\", keys[phi[-1]])\n",
    "                delta[1] = max(tmp2)\n",
    "\n",
    "                for i in range(2, len(obs)):\n",
    "                    tmp = self.observation_proba[self.X_index[self.get_X_index(obs[i][0])]]\\\n",
    "                                                        [self.Y_index[obs[i - 1][1]]]\\\n",
    "                            * self.transition_proba[self.Y_index[obs[i - 2][1]]][self.Y_index[obs[i - 1][1]]]\\\n",
    "                            * delta[i - 1]\n",
    "                    phi.append(np.argmax(tmp))\n",
    "                    print(\"tag\", (i - 1), obs[i - 1][1])\n",
    "                    print(\"Letter\", i, obs[i][0])\n",
    "                    print(\"Obs : curr_obs\", obs[i][0],\n",
    "                      \"last tag\", obs[i - 1][1], \n",
    "                      \":\", dict(zip(keys, self.observation_proba[self.X_index[self.get_X_index(obs[i][0])]]\\\n",
    "                                                    [self.Y_index[obs[i - 1][1]]])))\n",
    "                    print(\"Transition :\", \"y - 2 :\", obs[i - 2][1], \":\",\n",
    "                          \"y - 1 :\", obs[i - 1][1], \":\",\n",
    "                      dict(zip(keys, self.transition_proba[self.Y_index[obs[i - 2][1]]][self.Y_index[obs[i - 1][1]]])))\n",
    "                    print(\"Tmp\", tmp)\n",
    "                    print(\"Chosen letter :\", keys[phi[-1]])\n",
    "                    delta[i] = max(tmp)\n",
    "                return [keys[ind] for ind in phi]\n",
    "        \n",
    "        def score_viterbi(self, test):\n",
    "            error = 0\n",
    "            elements = 0\n",
    "            errors_corrected = 0\n",
    "            errors_added = 0\n",
    "            for word in test:\n",
    "                base = [letter for (letter, _) in word]\n",
    "                truth = [tag for (_, tag) in word]\n",
    "                preds = self.viterbi(word)\n",
    "                elements += len(preds)\n",
    "                for x, y, pred in zip(base, truth, preds):\n",
    "                    if pred != x and pred == y:\n",
    "                        errors_corrected += 1\n",
    "                    if pred != y:\n",
    "                        error += 1\n",
    "                        if x == y:\n",
    "                            errors_added += 1\n",
    "            return error / elements, errors_corrected, errors_added\n",
    "\n",
    "        def score_dummy(self, test):\n",
    "            error = 0\n",
    "            elements = 0\n",
    "            for word in test:\n",
    "                base = [letter for (letter, _) in word]\n",
    "                truth = [tag for (_, tag) in word]\n",
    "                elements += len(truth)\n",
    "                for x, y in zip(base, truth):\n",
    "                    if x != y:\n",
    "                        error += 1\n",
    "            return error / elements\n",
    "        \n",
    "        def results_hmm(self, test):\n",
    "            viterbi_error_test, vit_corrected, vit_added = self.score_viterbi(test)\n",
    "            error_dummy = self.score_dummy(test)\n",
    "            print(\"Error viterbi = {:.2%}, {} errors corrected, {} errors added\"\n",
    "                  .format(viterbi_error_test, vit_corrected, vit_added))\n",
    "            print(\"Error with nothing changed = {:.2%}\".format(error_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus with 10% errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM created with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "obs_list, state_list = distrib_x_y_data(train10)\n",
    "\n",
    "hmm2 = HMM_2(state_list, obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm2.init_parameters(train10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base : [('p', 'l'), ('j', 'i'), ('b', 'b'), ('e', 'e'), ('r', 'r'), ('a', 'a'), ('t', 't'), ('i', 'i'), ('o', 'o'), ('n', 'n')]\n",
      "tag 0 l\n",
      "Letter 1 j\n",
      "Obs : curr_obs j last tag l : {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.0, 'i': 0.8095238095238095, 'r': 0.0, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.14285714285714285, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.047619047619047616, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 1 : l : {'b': 0.0, 'y': 0.12646416517768513, 't': 0.022632519356759976, 'h': 0.0, 'e': 0.22394282310899344, 'i': 0.11911852293031566, 'r': 0.003772086559459996, 'o': 0.11117728806829462, 'w': 0.002183839587055787, 'n': 0.0003970617431010522, 'a': 0.06829461981338097, 'c': 0.0011911852293031567, 'u': 0.03295612467738734, 'v': 0.01568393885249156, 'l': 0.1415525114155251, 's': 0.03216200119118523, 'f': 0.017470716696446297, 'm': 0.006750049632717888, 'd': 0.06948580504268413, 'g': 0.0, 'k': 0.0023823704586063135, 'p': 0.0023823704586063135, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp2 {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.0, 'i': 0.00429850870861406, 'r': 0.0, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.0002098683663617453, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 5.0570690689577176e-06, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Chosen letter : i\n",
      "tag 1 i\n",
      "Letter 2 b\n",
      "Obs : curr_obs b last tag i : {'b': 0.5106382978723404, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.0, 'i': 0.0, 'r': 0.0, 'o': 0.0, 'w': 0.0, 'n': 0.3971631205673759, 'a': 0.0, 'c': 0.0, 'u': 0.0, 'v': 0.07801418439716312, 'l': 0.0, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.014184397163120567, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : l : y - 1 : i : {'b': 0.008270473383804145, 'y': 0.0, 't': 0.12687145539281622, 'h': 0.023297523846811503, 'e': 0.1969818158357971, 'i': 0.0, 'r': 0.0, 'o': 0.08148992847877862, 'w': 0.0, 'n': 0.11005008170831454, 'a': 0.07807130800631493, 'c': 0.060399640805170844, 'u': 0.0, 'v': 0.02993018455651941, 'l': 0.0, 's': 0.10656648230422085, 'f': 0.017996912128201665, 'm': 0.037386666835808526, 'd': 0.05355565218642891, 'g': 0.03377952115464478, 'k': 0.009143588291412211, 'p': 0.021572334571742773, 'z': 0.004636430513212962, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [1.81535499e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.87878505e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00369273e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.05959668e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : n\n",
      "tag 2 b\n",
      "Letter 3 e\n",
      "Obs : curr_obs e last tag b : {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.9974391805377721, 'i': 0.0, 'r': 0.002560819462227913, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.0, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : i : y - 1 : b : {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.4669312216017324, 'i': 0.2510801334441563, 'r': 0.0, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.08077815690866702, 'v': 0.0, 'l': 0.20121048804544417, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.75016883e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : e\n",
      "tag 3 e\n",
      "Letter 4 r\n",
      "Obs : curr_obs r last tag e : {'b': 0.0, 'y': 0.0, 't': 0.0045792787635947334, 'h': 0.0, 'e': 0.005724098454493417, 'i': 0.0, 'r': 0.9879793932455638, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.0, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0017172295363480253, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : b : y - 1 : e : {'b': 0.0, 'y': 0.032983182523699195, 't': 0.10363080755645486, 'h': 0.022456302476389224, 'e': 0.1683852913106548, 'i': 0.09073124049131998, 'r': 0.09232056992379015, 'o': 0.0, 'w': 0.0, 'n': 0.09473049145457339, 'a': 0.07023629005879377, 'c': 0.0532498127446894, 'u': 0.0, 'v': 0.0, 'l': 0.07236002037116411, 's': 0.09912424333841845, 'f': 0.016232099057450145, 'm': 0.0, 'd': 0.05549383780634616, 'g': 0.02806581088625643, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [0.00000000e+00 0.00000000e+00 4.15243074e-08 0.00000000e+00\n",
      " 8.43388510e-08 0.00000000e+00 7.98110080e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.43904306e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : r\n",
      "tag 4 r\n",
      "Letter 5 a\n",
      "Obs : curr_obs a last tag r : {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.0, 'i': 0.0, 'r': 0.0, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.9878682842287695, 'c': 0.0, 'u': 0.0, 'v': 0.0, 'l': 0.0, 's': 0.012131715771230503, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : e : y - 1 : r : {'b': 0.0057026502072741415, 'y': 0.031048517960477848, 't': 0.09306082131641766, 'h': 0.01836830394285366, 'e': 0.1675438089907566, 'i': 0.08929359890904913, 'r': 0.06358588352511588, 'o': 0.06335995338104695, 'w': 0.006851535685446987, 'n': 0.07493710245840875, 'a': 0.06486297872449952, 'c': 0.037857429325820174, 'u': 0.0, 'v': 0.018899982189431452, 'l': 0.06061870887010723, 's': 0.07945773896697139, 'f': 0.012253640764131886, 'm': 0.0288610934287057, 'd': 0.04044616206874166, 'g': 0.026050895122173214, 'k': 0.0, 'p': 0.0169391941625702, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.11397649e-07 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.69345159e-09\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : a\n",
      "tag 5 a\n",
      "Letter 6 t\n",
      "Obs : curr_obs t last tag a : {'b': 0.0, 'y': 0.003683241252302026, 't': 0.9760589318600368, 'h': 0.0, 'e': 0.0, 'i': 0.0, 'r': 0.01780233271945979, 'o': 0.0, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.0, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0006138735420503376, 'm': 0.0, 'd': 0.0, 'g': 0.001841620626151013, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : r : y - 1 : a : {'b': 0.010131795605697633, 'y': 0.0410708017216492, 't': 0.14747197820489555, 'h': 0.0, 'e': 0.0, 'i': 0.11249082977379869, 'r': 0.09434132810395449, 'o': 0.0, 'w': 0.009048384765579794, 'n': 0.11441256170066093, 'a': 0.0, 'c': 0.056272618539368956, 'u': 0.0, 'v': 0.02868250417610622, 'l': 0.10165269465143907, 's': 0.10612737237181688, 'f': 0.016116831928470323, 'm': 0.03809927851208671, 'd': 0.057187401469977715, 'g': 0.03701955803131185, 'k': 0.0, 'p': 0.026172861929629906, 'z': 0.002024296875625295, 'j': 0.0, 'x': 0.0, 'q': 0.0016769016379307416}\n",
      "Tmp [0.00000000e+00 7.73609998e-11 7.36112637e-08 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.58890159e-10 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.05961324e-12 0.00000000e+00 0.00000000e+00 3.48650368e-11\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : t\n",
      "tag 6 t\n",
      "Letter 7 i\n",
      "Obs : curr_obs i last tag t : {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.0, 'i': 0.9788688626476072, 'r': 0.0, 'o': 0.01678060907395898, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.00435052827843381, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : a : y - 1 : t : {'b': 0.0, 'y': 0.0, 't': 0.1136407582058911, 'h': 0.031518311709458825, 'e': 0.20421700153149674, 'i': 0.1329974321938986, 'r': 0.08286537755807118, 'o': 0.07037637387841025, 'w': 0.0, 'n': 0.0, 'a': 0.07667167467613185, 'c': 0.04632211888408294, 'u': 0.03652465265017256, 'v': 0.0, 'l': 0.07550161925701916, 's': 0.09673341898934022, 'f': 0.0, 'm': 0.03263126046602665, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 9.58323291e-09 0.00000000e+00 8.69318415e-11\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.16969427e-11 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : i\n",
      "tag 7 i\n",
      "Letter 8 o\n",
      "Obs : curr_obs o last tag i : {'b': 0.0, 'y': 0.0, 't': 0.0, 'h': 0.0, 'e': 0.0, 'i': 0.0, 'r': 0.0, 'o': 0.9753521126760564, 'w': 0.0, 'n': 0.0, 'a': 0.0, 'c': 0.0, 'u': 0.0, 'v': 0.0, 'l': 0.018779342723004695, 's': 0.0, 'f': 0.0, 'm': 0.0, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.005868544600938967, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : t : y - 1 : i : {'b': 0.007341113818513494, 'y': 0.0, 't': 0.10890664772973223, 'h': 0.0, 'e': 0.17385981200812356, 'i': 0.0, 'r': 0.0733328789304673, 'o': 0.08634938510666663, 'w': 0.0, 'n': 0.09734958787334559, 'a': 0.06850220093898696, 'c': 0.05483290832491815, 'u': 0.0, 'v': 0.03038361072707585, 'l': 0.07274585357152415, 's': 0.09882016535061854, 'f': 0.01590356909845215, 'm': 0.032972331652591454, 'd': 0.04676658721668141, 'g': 0.02896883895002865, 'k': 0.0, 'p': 0.0, 'z': 0.002964508702273928, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.07109988e-10\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.30918396e-11 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : o\n",
      "tag 8 o\n",
      "Letter 9 n\n",
      "Obs : curr_obs n last tag o : {'b': 0.0005633802816901409, 'y': 0.0, 't': 0.0, 'h': 0.0005633802816901409, 'e': 0.0, 'i': 0.0, 'r': 0.0, 'o': 0.0, 'w': 0.0, 'n': 0.9864788732394366, 'a': 0.0, 'c': 0.0, 'u': 0.0, 'v': 0.0, 'l': 0.0, 's': 0.0, 'f': 0.0, 'm': 0.012394366197183098, 'd': 0.0, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Transition : y - 2 : i : y - 1 : o : {'b': 0.0, 'y': 0.0, 't': 0.18577375528605383, 'h': 0.0, 'e': 0.0, 'i': 0.0, 'r': 0.15719037460030083, 'o': 0.0, 'w': 0.0, 'n': 0.20896733350866414, 'a': 0.0, 'c': 0.0, 'u': 0.0699417335743312, 'v': 0.0, 'l': 0.13742583493322566, 's': 0.1558732510301053, 'f': 0.0, 'm': 0.0, 'd': 0.08482771706731887, 'g': 0.0, 'k': 0.0, 'p': 0.0, 'z': 0.0, 'j': 0.0, 'x': 0.0, 'q': 0.0}\n",
      "Tmp [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.66379154e-10 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Chosen letter : n\n",
      "Predicted ['p', 'i', 'n', 'e', 'r', 'a', 't', 'i', 'o', 'n']\n"
     ]
    }
   ],
   "source": [
    "word = train10[11]\n",
    "print(\"Base :\", word)\n",
    "print(\"Predicted\", hmm2.viterbi(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error viterbi = 8.70%, 371 errors corrected, 263 errors added\n",
      "Error with nothing changed = 10.18%\n"
     ]
    }
   ],
   "source": [
    "hmm2.results_hmm(test10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus with 20% errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM created with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "obs_list, state_list = distrib_x_y_data(train20)\n",
    "\n",
    "hmm2_20 = HMM_2(state_list, obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error viterbi = 15.42%, 1636 errors corrected, 970 errors added\n",
      "Error with nothing changed = 19.41%\n"
     ]
    }
   ],
   "source": [
    "hmm2_20.init_parameters(train20)\n",
    "\n",
    "hmm2_20.results_hmm(test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TC4-tp2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
