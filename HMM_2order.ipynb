{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train10 :  29057\n",
      "length of train20 :  27184\n",
      "length of test10 :  1501\n",
      "length of test20 :  3374\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "train10 = pickle.load( open( \"./typos-data/train10.pkl\", \"rb\" ) )\n",
    "train20 = pickle.load( open( \"./typos-data/train20.pkl\", \"rb\" ) )\n",
    "test10 = pickle.load( open( \"./typos-data/test10.pkl\", \"rb\" ) )\n",
    "test20 = pickle.load( open( \"./typos-data/test20.pkl\", \"rb\" ) )\n",
    "print(\"length of train10 : \",len(train10))\n",
    "print(\"length of train20 : \",len(train20))\n",
    "print(\"length of test10 : \",len(test10))\n",
    "print(\"length of test20 : \",len(test20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_list=[]\n",
    "state_list=[]\n",
    "for mot in train10:\n",
    "    for (l1,l2) in mot:\n",
    "        observation_list.append(l1)\n",
    "        state_list.append(l2)\n",
    "observation_list=list(set(observation_list))\n",
    "state_list=list(set(state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import numpy as np\n",
    "import sys\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# construc the first order HMM Model\n",
    "\n",
    "UNK = \"<unk>\"\n",
    "UNKid = 0\n",
    "epsilon = 1e-100\n",
    "\n",
    "class HMM2:\n",
    "        def __init__(self, state_list, observation_list, train,test,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None, smoothing_obs = 0.01):\n",
    "            \"\"\"\n",
    "            Builds a Hidden Markov Model\n",
    "            * state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            * observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            * transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            * observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            * initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print(\"HMM creating with: \")\n",
    "            self.N = len(state_list)       # number of states\n",
    "            self.M = len(observation_list) # number of possible emissions\n",
    "            print(str(self.N)+\" states\")\n",
    "            print(str(self.M)+\" observations\")\n",
    "            self.train=train\n",
    "            self.omega_Y = state_list\n",
    "            self.omega_X = observation_list\n",
    "#             self.A2=zeros( (self.N*self.N,self.N), float)\n",
    "            self.A2=zeros( (self.N,self.N,self.N), float)\n",
    "            self.B2=zeros( (self.N*self.N,self.M), float)\n",
    "            self.pi2=zeros( (self.N*self.N), float)\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.N, self.M), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros( (self.N,), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            self.make_indexes() # build indexes, i.e the mapping between token and int\n",
    "#             self.make_2indexes()\n",
    "            self.data2index()\n",
    "            self.calculer_pi()\n",
    "            self.calculer_A()\n",
    "            self.calculer_B()\n",
    "#             self.calculer_pi2()\n",
    "            self.calculer_A2()\n",
    "#             self.calculer_B2()\n",
    "            \n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities array\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "\n",
    "        \n",
    "        def data2index(self):\n",
    "            self.Y_char={}\n",
    "            for i in self.Y_index:\n",
    "                self.Y_char[self.Y_index[i]]=i\n",
    "        \n",
    "        def calculer_pi(self):\n",
    "            for word in self.train:\n",
    "                self.initial_state_proba[self.Y_index[word[0][1]]]+=1\n",
    "#             print(self.initial_state_proba)\n",
    "            self.initial_state_proba/=len(self.train)\n",
    "        \n",
    "    \n",
    "        def calculer_A(self):\n",
    "            s=0\n",
    "            for word in self.train:\n",
    "                for i in range(len(word)-1):\n",
    "                    s+=1\n",
    "                    w1=self.Y_index[word[i][1]]\n",
    "                    w2=self.Y_index[word[i+1][1]]\n",
    "                    self.transition_proba[w1][w2]+=1\n",
    "            tmp=self.transition_proba.T\n",
    "            self.transition_proba=(tmp/self.transition_proba.sum(axis=1)).T\n",
    "#             self.transition_proba/=self.transition_proba.sum(axis=0)\n",
    "        \n",
    "        def calculer_B(self):\n",
    "            s=0\n",
    "            for word in self.train:\n",
    "                for i in range(len(word)):\n",
    "                    s+=1\n",
    "                    w1=self.Y_index[word[i][1]]\n",
    "                    w2=self.X_index[word[i][0]]\n",
    "                    self.observation_proba[w1][w2]+=1\n",
    "            tmp=self.observation_proba.T\n",
    "            self.observation_proba=(tmp/self.observation_proba.sum(axis=1)).T\n",
    "            \n",
    "        def calculer_A2(self):\n",
    "            for word in self.train:\n",
    "                for i in range(2,len(word)):\n",
    "                    w1=self.Y_index[word[i-2][1]]\n",
    "                    w2=self.Y_index[word[i-1][1]]\n",
    "                    w3=self.Y_index[word[i][1]]\n",
    "                    self.A2[w1,w2,w3]+=1\n",
    "            sumPlus1 = self.A2.sum(axis=0).reshape(self.N, self.N)\n",
    "            self.A2 /= np.where(sumPlus1 == 0, 1, sumPlus1)\n",
    "#             self.A2=self.A2/self.A2.sum(axis=0).reshape(self.N,self.N)       \n",
    "            \n",
    "        def viterbi(self,word):\n",
    "            if len(word)<2:\n",
    "                return word[0][0]\n",
    "            N=len(self.Y_index)\n",
    "            delta=np.zeros((N,N,len(word)),float)\n",
    "            tmp=np.zeros((N,N),float)\n",
    "            delta1=np.zeros(N, float) \n",
    "            index=np.zeros((N,N,len(word)),float) \n",
    "            result=[0]*len(word)\n",
    "            delta1=self.initial_state_proba*self.observation_proba[:,self.X_index[word[0][0]]]\n",
    "            for i in range (0,N):\n",
    "                for j in range (0,N):\n",
    "                    delta[i,j,1] = delta1[i]*self.transition_proba[i,j]*self.observation_proba[j,self.X_index[word[1][0]]]\n",
    "            for t in range(2,len(word)): \n",
    "                p=self.X_index[word[t][0]]\n",
    "                for i in range (0,N):\n",
    "                    for j in range (0,N):\n",
    "                        tmp=delta[:,i,t-1]*self.A2[:,i,j]\n",
    "                        delta[i,j,t]=max(tmp)\n",
    "                        index[i,j,t]=tmp.argmax()\n",
    "                        delta[i,j,t]=delta[i,j,t]*self.observation_proba[j,p]\n",
    "            delta_t=delta[:,:,len(word)-1]\n",
    "            result[len(word)-1]=np.unravel_index(delta_t.argmax(),delta_t.shape)[1]\n",
    "            result[len(word)-2]=np.unravel_index(delta_t.argmax(),delta_t.shape)[0]            \n",
    "            for t in range(len(word)-3,-1,-1): \n",
    "                result[t] = index[int(result[t+1]),int(result[t+2]),t+2]\n",
    "            r=[self.Y_char[i] for i in result]\n",
    "            return r\n",
    "        \n",
    "        def score_viterbi(self, test):\n",
    "            s=0\n",
    "            e=0\n",
    "            correct=0\n",
    "            creat=0\n",
    "            for word in test:\n",
    "                nword=self.viterbi(word)\n",
    "                for i,j in zip(word,nword):\n",
    "                    s+=1\n",
    "                    if i[1]!=j:\n",
    "                        e+=1\n",
    "                    if i[0]!=i[1] and i[1]==j:\n",
    "                        correct+=1\n",
    "                    if i[1]!=j and i[0]==i[1]:\n",
    "                        creat+=1\n",
    "            return {\"Error rate\":e/s, \"Errors correct\":correct, \"Errors creat\":creat}\n",
    "        def baseline(self,test):\n",
    "            s=0\n",
    "            e=0\n",
    "            for word in test:\n",
    "                for l in word:\n",
    "                    s+=1\n",
    "                    if l[0]!=l[1]:\n",
    "                        e+=1\n",
    "            return e/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n",
      "Test10, trained with train10:\n",
      "Baseline: 0.10177595628415301\n",
      "Viterbe for test10: {'Error rate': 0.05423497267759563, 'Errors correct': 473, 'Errors creat': 125}\n"
     ]
    }
   ],
   "source": [
    "model1=HMM2(state_list,observation_list,train10,None)\n",
    "print(\"Test10, trained with train10:\")\n",
    "print(\"Baseline:\",model1.baseline(test10))\n",
    "print(\"Viterbe for test10:\",model1.score_viterbi(test10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjx/.local/lib/python3.6/site-packages/ipykernel_launcher.py:115: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test20, trained with train20:\n",
      "Baseline: 0.19405667725121323\n",
      "Viterbe for test20: {'Error rate': 0.09633934455694686, 'Errors correct': 2095, 'Errors creat': 464}\n"
     ]
    }
   ],
   "source": [
    "model2=HMM2(state_list,observation_list,train20,None)\n",
    "print(\"Test20, trained with train20:\")\n",
    "print(\"Baseline:\",model2.baseline(test20))\n",
    "print(\"Viterbe for test20:\",model2.score_viterbi(test20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
